import optuna
import pandas as pd
import numpy as np
import os
import torch
import torch.nn as nn

# --- Library Imports ---
from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor
from sb3_contrib import RecurrentPPO # We use the Recurrent (LSTM) PPO
from stable_baselines3.common.evaluation import evaluate_policy
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.monitor import Monitor

# --- Local Imports ---
import dataloading
from trading_env import TradingEnv

# --- Constants ---
TRAIN_FILE = "data/processed_train.csv"
VAL_FILE = "data/processed_val.csv"

def load_data_for_tuning():
    """
    Loads raw data and processed features, then aligns them exactly by index.
    """
    print("--- Loading Data for Tuning ---")
    
    # 1. Load Raw Data (Prices) using the NEW function
    df_full = dataloading.get_full_dataset()
    
    # 2. Slice Raw Data to match our Regime (Train < 2024, Val = 2024)
    VAL_START = pd.Timestamp("2024-01-01", tz="UTC")
    TEST_START = pd.Timestamp("2025-01-01", tz="UTC")
    
    df_raw_train = df_full[df_full.index < VAL_START].copy()
    df_raw_val = df_full[(df_full.index >= VAL_START) & (df_full.index < TEST_START)].copy()
    
    # 3. Load Processed Features (Generated by main.py)
    if not os.path.exists(TRAIN_FILE) or not os.path.exists(VAL_FILE):
        raise FileNotFoundError("Processed data not found! Run main.py first.")
        
    df_features_train = pd.read_csv(TRAIN_FILE, index_col=0, parse_dates=True)
    df_features_val = pd.read_csv(VAL_FILE, index_col=0, parse_dates=True)
    
    # 4. ALIGNMENT (Crucial Step)
    # Ensure raw prices and features have exactly the same rows
    common_train = df_raw_train.index.intersection(df_features_train.index)
    df_raw_train = df_raw_train.loc[common_train]
    df_features_train = df_features_train.loc[common_train]
    
    common_val = df_raw_val.index.intersection(df_features_val.index)
    df_raw_val = df_raw_val.loc[common_val]
    df_features_val = df_features_val.loc[common_val]
    
    print(f"Training Data: {len(df_features_train)} rows")
    print(f"Validation Data: {len(df_features_val)} rows")
    
    return df_features_train, df_raw_train, df_features_val, df_raw_val

# Load data once globally to save time during tuning
DF_FEAT_TRAIN, DF_RAW_TRAIN, DF_FEAT_VAL, DF_RAW_VAL = load_data_for_tuning()

def objective(trial):
    """
    Optuna Objective Function (HPC OPTIMIZED):
    Tests Architecture, Hyperparams, and LSTM size together.
    """
    
    # --- 1. Suggest Hyperparameters ---
    learning_rate = trial.suggest_float("learning_rate", 1e-5, 5e-4, log=True)
    gamma = trial.suggest_float("gamma", 0.95, 0.995)
    gae_lambda = trial.suggest_float("gae_lambda", 0.90, 1.0)
    ent_coef = trial.suggest_float("ent_coef", 1e-6, 0.01, log=True)
    max_grad_norm = trial.suggest_float("max_grad_norm", 0.3, 1.0)
    
    # --- HPC SCALING: Architecture Search ---
    # Vi lader Optuna bestemme om netværket skal være lille og hurtigt, eller stort og dybt.
    net_arch_type = trial.suggest_categorical("net_arch", ["small", "medium", "large"])
    
    if net_arch_type == "small":
        # 2 lag af 64 neuroner (Standard)
        net_arch = dict(pi=[64, 64], vf=[64, 64])
    elif net_arch_type == "medium":
        # 2 lag af 128 neuroner
        net_arch = dict(pi=[128, 128], vf=[128, 128])
    elif net_arch_type == "large":
        # 2 lag af 256 neuroner (Kræver mere data, men kan fange komplekse mønstre)
        net_arch = dict(pi=[256, 256], vf=[256, 256])

    # LSTM Specifics (Udvidet til HPC)
    n_steps = trial.suggest_categorical("n_steps", [2048, 4096, 8192])
    batch_size = trial.suggest_categorical("batch_size", [512, 1024, 2048])
    lstm_hidden_size = trial.suggest_categorical("lstm_hidden", [128, 256, 512])
    
    # Constraint: Batch size must be a factor of n_steps (or smaller)
    if batch_size > n_steps:
        batch_size = n_steps

    # --- 2. Setup Environments ---
    # We use a simple DummyVecEnv for tuning speed
    train_env = DummyVecEnv([lambda: TradingEnv(DF_FEAT_TRAIN, DF_RAW_TRAIN)])
    val_env = DummyVecEnv([lambda: Monitor(TradingEnv(DF_FEAT_VAL, DF_RAW_VAL))])
    
    # --- 3. Define Model (RecurrentPPO) ---
    model = RecurrentPPO(
        "MlpLstmPolicy",
        train_env,
        learning_rate=learning_rate,
        n_steps=n_steps,
        batch_size=batch_size,
        gamma=gamma,
        gae_lambda=gae_lambda,
        ent_coef=ent_coef,
        max_grad_norm=max_grad_norm,
        policy_kwargs=dict(
            enable_critic_lstm=True,
            lstm_hidden_size=lstm_hidden_size,
            net_arch=net_arch, # <-- Dynamisk arkitektur indsat her
            activation_fn=nn.Tanh
        ),
        verbose=0,
        device="cuda" if torch.cuda.is_available() else "cpu"
    )
    
    # --- 4. Train with Early Stopping ---
    
    # Vi øger eval_freq fordi n_steps er større.
    # Vi vil ikke evaluere midt i en rollout.
    eval_freq = max(20000, n_steps)
    
    eval_callback = EvalCallback(
        val_env, 
        best_model_save_path=None,
        log_path=None, 
        eval_freq=eval_freq,
        deterministic=True, 
        render=False
    )
    
    try:
        # Train for 500,000 steps (HPC har råd til lidt længere runs per trial)
        model.learn(total_timesteps=500000, callback=eval_callback)
    except Exception as e:
        print(f"Trial failed with error: {e}")
        # Returner en meget lav score så Optuna undgår disse parametre
        return -1000 
        
    # --- 5. Evaluate Performance ---
    # Vi bruger Mean Reward på Valideringssættet
    mean_reward, std_reward = evaluate_policy(model, val_env, n_eval_episodes=5)
    
    # Optuna gemmer også netværks-typen, så vi kan se om "large" er bedre end "small"
    trial.set_user_attr("net_arch", net_arch_type)
    
    return mean_reward

def run_tuning():
    print("--- Starting Optuna Tuning (HPC Mode) ---")
    
    # Create study to MAXIMIZE reward
    study = optuna.create_study(direction="maximize")
    
    # Kør 500 trials. Dette vil tage tid, men med HPC finder vi den bedste model.
    print("Running 500 trials. This is a brute-force optimization.")
    study.optimize(objective, n_trials=500, show_progress_bar=True)
    
    print("\n--- Tuning Complete ---")
    print("Best Params:", study.best_params)
    print("Best Value:", study.best_value)
    
    # Save best params to file so trade.py can read them
    with open("best_hyperparams.txt", "w") as f:
        # Vi skal huske at inkludere net_arch logikken i outputtet, 
        # da best_params kun indeholder "net_arch": "large" (strengen), ikke ordbogen.
        # Men trade.py skal opdateres til at læse dette (det gør vi i næste trin).
        f.write(str(study.best_params))
        
if __name__ == "__main__":
    run_tuning()